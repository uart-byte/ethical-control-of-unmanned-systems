## NPS contributions toward achieving run-time ethical constraints in mission execution by autonomous robots and human/robot teams

1. NPS began research on autonomous underwater vehicles (AUV) in the early 1990's. The first vehicle, tested at sea in the mid-1990's, was "Phoenix". This vehicle length was around 6 ft., weight approximately 600 lb. At that time, the onboard control system was called RBM for "Rational Behavior Model". RBM was modeled on standard naval practice for deployment and operation of manned submarines at the time. 

2. The top level of the three layer RBM software architecture assumed that AI was required to replace the function of a submarine commander. Specifically, we believed that first order logic (predicate calculus) would be needed for mathematical modeling and programming of a commander's function. Therefore a separate "SPARC" workstation running "Prolog" language was included in Phoenix. RBM functioned well in Phoenix at sea testing.

3. In early 2000's, Phoenix was replaced by a larger vehicle called "Aries", that contained a more advanced on board sensor suite, larger batteries, and more powerful main propulsion thrusters. Aries was about 1000 lb. in weight and 8 feet long, and capable of longer duration and more complex missions than its predecessor. Experience with Phoenix led us to full practical realization that mission control based on human style reasoning (predicate logic) cannot, (in general) be proved correct for a given mission. Fortunately, we also came to realize that "finite state" logic is adequate for any mission control tasks we actually anticipated carrying out by autonomous vehicles. In contrast to our experience with Phoenix, for Aries we were able to prove by exhaustion of all possible outcomes that its missions were correctly programmed (that is, that they accomplished what we intended). Aries was a success, and was retired after completion of all planned mission tasks. All results were published.

4. Early in the current decade, we began to realize that responsible experimentation with larger and more powerful robots (AUVs or others) would require that some run-time ethical constraints be incorporated into their mission control software. This was not done for Phoenix or Aries. As we addressed this requirement, it become apparent to us that inclusion of such constraints requires a possible "exception" outcome of execution of a mission phase goal (command) in addition to the "success" and "failure" outcomes we had previously considered. This understanding was summarized in our 2018 JOE paper that was based on such "tri-state" logic.

5. Since publication of our 2018 paper, we have been concerned with implementation details for tri-state mission logic for autonomous robots and human/robot teams. To date, we have demonstrated, in human interactive form, execution of a simulated  8-state "sailor overboard" mission by a human/robot team, using either Prolog or Common Lisp as a programming language. We expect soon to complete an XML implementation.

6. A key aspect of tri-state logic, including possible violation of an ethical constraint, either pending or actual, is the need for constant situational awareness by mission control software. We believe that mandating this type of software for mission control could possibly have prevented loss of human life in recent passenger aircraft and self-driving car accidents. We urge further research on this issue ASAP.

Robert McGhee, NPS
